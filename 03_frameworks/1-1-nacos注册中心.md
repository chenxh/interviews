https://mp.weixin.qq.com/s/ZlrYq7bxPwk3IYmHGFO6XA
https://mp.weixin.qq.com/s/EdZpO5615J4_fzeud9Greg

## nacos 的数据模型
在Nacos中，一个服务的确定是由三部分信息确定

* 命名空间（Namespace）：多租户隔离用的，默认是public
* 分组（Group）：这个其实可以用来做环境隔离，服务注册时可以指定服务的分组，比如是测试环境或者是开发环境，默认是DEFAULT_GROUP
* 服务名（ServiceName）：这个就不用多说了
通过上面三者就可以确定同一个服务了

在服务注册和订阅的时候，必须要指定上述三部分信息，如果不指定，Nacos就会提供默认的信息

不过，在Nacos中，在服务里面其实还是有一个集群的概念。

![](https://github.com/chenxh/interviews/blob/main/imgs/nacos-model.png "nacos-model.png") 



## 临时实例和永久实例
**临时实例**
临时实例在注册到注册中心之后仅仅只保存在服务端内部一个缓存中，不会持久化到磁盘。
这个服务端内部的缓存在注册中心届一般被称为服务注册表。
当服务实例出现异常或者下线之后，就会把这个服务实例从服务注册表中剔除。
**永久实例**
永久服务实例不仅仅会存在服务注册表中，同时也会被持久化到磁盘文件中。
当服务实例出现异常或者下线，Nacos只会将服务实例的健康状态设置为不健康，并不会对将其从服务注册表中剔除。
所以这个服务实例的信息你还是可以从注册中心看到，只不过处于不健康状态。

临时实例就比较适合于业务服务，服务下线之后可以不需要在注册中心中查看到。
永久实例就比较适合需要运维的服务，这种服务几乎是永久存在的，比如说MySQL、Redis等等

在1.x版本中，一个服务中可以既有临时实例也有永久实例，服务实例是永久还是临时是由服务实例本身决定的。

但是2.x版本中，一个服务中的所有实例要么都是临时的要么都是永久的，是由服务决定的，而不是具体的服务实例。

## 服务注册
服务注册，就是通过注册中心提供的客户端SDK（或者是控制台）将服务本身的一些元信息，比如ip、端口等信息发送到注册中心服务端。
服务端在接收到服务之后，会将服务的信息保存到前面提到的服务注册表中。

### 1.x版本的实现
服务注册是通过Http接口实现的。
nacos 客户端调用 nacos 服务端的 Controller 接口实现注册。

### 2.x版本的实现

**通信协议**
2.x版本相比于1.x版本最主要的升级就是客户端和服务端通信协议的改变，由1.x版本的Http改成了2.x版本gRPC。
gRPC是谷歌公司开发的一个高性能、开源和通用的RPC框架，Java版本的实现底层也是基于Netty来的。 此方案优化了性能。 
Http请求会频繁创建和销毁连接，白白浪费资源。

2.x版本服务端依然保留了Http注册的接口，所以用1.x的Nacos SDK依然可以注册到2.x版本的服务端。

**实现细节**
Nacos客户端在启动的时候，会通过gRPC跟服务端建立长连接。
这个连接会一直存在，之后客户端与服务端所有的通信都是基于这个长连接来的。
当客户端发起注册的时候，就会通过这个长连接，将服务实例的信息发送给服务端。

***redo操作***
当注册的是临时实例时，2.x还会将服务实例信息存储到客户端中的一个缓存中，供Redo操作。
所谓的Redo操作，其实就是一个补偿机制，本质是个定时任务，默认每3s执行一次。
这个定时任务作用是，当客户端与服务端重新建立连接时（因为一些异常原因导致连接断开）。
那么之前注册的服务实例肯定还要继续注册服务端（断开连接服务实例就会被剔除服务注册表）。
所以这个Redo操作一个很重要的作用就是重连之后的重新注册的作用。

### 服务注册总结
1.x版本是通过Http协议来进行服务注册的

2.x由于客户端与服务端的通信改成了gRPC长连接，所以改成通过gRPC长连接来注册

2.x比1.x多个Redo操作，当注册的服务实例是临时实例是，出现网络异常，连接重新建立之后，客户端需要将服务注册、服务订阅之类的操作进行重做

## 心跳机制
心跳机制，也可以被称为保活机制，它的作用就是服务实例告诉注册中心我这个服务实例还活着。
在Nacos中，心跳机制仅仅是针对临时实例来说的，临时实例需要靠心跳机制来保活。

### 1.x心跳实现
在1.x中，心跳机制实现是通过 ***客户端和服务端各存在的一个定时任务*** 来完成的。
在服务注册时，发现是临时实例，客户端会开启一个5s执行一次的定时任务。定时任务会构建一个Http请求，携带这个服务实例的信息，然后发送到服务端。
在Nacos服务端也会开启一个定时任务，默认也是5s执行一次，去检查这些服务实例最后一次心跳的时间，也就是客户端最后一次发送Http请求的时间。

1. 当最后一次心跳时间超过15s，但没有超过30s，会把这服务实例标记成不健康
2. 当最后一次心跳超过30s，直接把服务从服务注册表中剔除

其实1.x的这个心跳还有一个作用，就是跟上一节说的gRPC时Redo操作的作用是一样的。
服务在处理心跳的时候，发现心跳携带这个服务实例的信息在注册表中没有，此时就会添加到服务注册表。
所以心跳也有Redo的类似效果。

## 2.x心跳实现
2.x版本，主要是两种机制来进行保活：

连接本身的心跳机制，断开就直接剔除服务实例。
Nacos主动检查机制，服务端会对20s没有发送数据的连接进行检查，出现异常时也会主动断开连接，剔除服务实例。

**主动检测机制**

Nacos服务端也会启动一个定时任务，默认每隔3s执行一次

这个任务会去检查超过20s没有发送请求数据的连接

一旦发现有连接已经超过20s没发送请求，那么就会向这个连接对应的客户端发送一个请求

如果请求不通或者响应失败，此时服务端也会认为与客户端的这个连接异常，从而将这个客户端注册的服务实例从服务注册表中剔除

## 健康检查
对于永久实例来说，一般来说无法主动上报心跳。Nacos通过一种叫健康检查的机制去判断服务实例是否活着。
服务端主动向服务实例发送请求，去探测服务实例的健康状态。
健康检查机制在1.x和2.x的实现机制是一样的

Nacos服务端会去创建一个健康检查任务，这个任务每次执行时间间隔会在2000~7000毫秒之间。

当任务触发的时候，会根据设置的健康检查的方式执行不同的逻辑，目前主要有以下三种方式：

* TCP：TCP的方式就是根据服务实例的ip和端口去判断是否能连接成功，如果连接成功，就认为健康，反之就任务不健康
* HTTP： HTTP的方式就是向服务实例的ip和端口发送一个Http请求，请求路径是需要设置的，如果能正常请求，说明实例健康，反之就不健康
* MySQL： MySQL的方式是一种特殊的检查方式，执行sql来判断数据库是不是主库。
  
```show global variables where variable_name='read_only' ```


## 服务发现
服务发现就是指当有服务实例注册成功之后，其它服务可以发现这些服务实例。
Nacos提供了两种发现方式：
* ***主动查询***就是指客户端主动向服务端查询需要关注的服务实例，也就是拉（pull）的模式
* ***服务订阅***就是指客户端向服务端发送一个订阅服务的请求，当被订阅的服务有信息变动就会主动将服务实例的信息推送给订阅的客户端，本质就是推（push）模式


**主动查询**
1.x整体就是发送Http请求去查询服务实例，2.x只不过是将Http请求换成了gRPC的请求。

服务端对于查询的处理过程都是一样的，从服务注册表中查出符合查询条件的服务实例进行返回

**服务订阅**
1.x版本的服务订阅的实现
![](https://github.com/chenxh/interviews/blob/main/imgs/nacos-sub-v1.png "nacos-sub-v1")


第一步，客户端在启动的时候，会去构建一个叫PushReceiver的类。这个类会去创建一个UDP Socket，端口是随机的。

第二步，调用NamingService#subscribe来发起订阅时，会先去服务端查询需要订阅服务的所有实例信息。之后会将所有服务实例数据存到客户端的一个内部缓存中。
并且在查询的时候，***会将这个UDP Socket的端口作为一个参数传到服务端***。服务端接收到这个UDP端口后，后续就通过这个端口给客户端推送服务实例数据。

第三步，会为这次订阅开启一个不定时执行的任务。这个任务会去从服务端查询订阅的服务实例信息，然后更新内部缓存。

那就是因为UDP通信不稳定导致的。 虽然有Push，但是由于UDP通信自身的不确定性，有可能会导致客户端接收变动信息失败。 所以这里就加了一个定时任务，弥补这种可能性，属于一个兜底的方案。


2.x服务订阅的实现
![](https://github.com/chenxh/interviews/blob/main/imgs/nacos-sub-v2.png "nacos-sub-v2")

2.x版本换成了gRPC长连接的方式，所以2.x版本服务数据变更推送已经完全抛弃了1.x的UDP做法。当有服务实例变动的时候，服务端直接通过这个长连接将服务信息发送给客户端。 客户端拿到最新服务实例数据之后的处理方式就跟1.x是一样了。

定时对比机制也保留了，只不过这个定时对比的机制默认是关闭状态。


***2.x版本中，只支持订阅临时服务，对于永久服务，已经不支持订阅了***


## nacos 集群得数据一致性
nacos 部署集群模式时， 每个节点管理不同的服务实例， 每个节点的注册表是全部的服务实例数据。


### nacos的AP和CP
Nacos其实目前是同时支持AP和CP的。

具体使用AP还是CP得取决于Nacos内部的具体功能，并不是有的文章说的可以通过一个配置自由切换。

就以服务注册举例来说，对于临时实例来说，Nacos会优先保证可用性，也就是AP 。

对于永久实例，Nacos会优先保证数据的一致性，也就是CP 。



### nacos 的AP实现
对于AP来说，Nacos使用的是阿里自研的Distro协议。
在这个协议中，每个服务端节点是一个平等的状态，每个服务端节点正常情况下数据是一样的，每个服务端节点都可以接收来自客户端的读写请求。

实现方案：
* 当某个节点刚启动时，他会向集群中的某个节点发送请求，拉取所有的服务实例数据到自己的服务注册表中。
* 当某个服务端节点接收到注册临时服务实例的请求，不仅仅会将这个服务实例存到自身的服务注册表，同时也会向其它所有服务节点发送请求，将这个服务数据同步到其它所有节点。

数据同步出问题时，通过***失败重试机制***和***定时对比机制*** 保证数据最终一致。
***失败重试机制***
数据同步给其它节点失败时，会每隔3s重试一次，直到成功。

***定时对比机制***
每个Nacos服务节点会定时向所有的其它服务节点发送一些认证的请求。

这个请求会告诉每个服务节点自己负责的服务实例的对应的版本号，这个版本号随着服务实例的变动就会变动。

如果其它服务节点的数据的版本号跟自己的对不上，那就说明其它服务节点的数据不是最新的。

此时这个Nacos服务节点就会将自己负责的服务实例数据发给不是最新数据的节点，这样就保证了每个节点的数据是一样的了。



### nacos的CP实现

Nacos的CP实现是基于Raft算法来实现的。 zookeeper 也是CP。

在2.x版本，Nacos移除了手动实现Raft算法，转而拥抱基于蚂蚁开源的JRaft框架

在Raft算法，每个节点主要有三个状态

Leader，负责所有的读写请求，一个集群只有一个
Follower，从节点，主要是负责复制Leader的数据，保证数据的一致性
Candidate，候选节点，最终会变成Leader或者Follower
集群启动时都是节点Follower，经过一段时间会转换成Candidate状态，再经过一系列复杂的选择算法，选出一个Leader。

当有写请求时，如果请求的节点不是Leader节点时，会将请求转给Leader节点，由Leader节点处理写请求。

首先，Leader在处理写请求时，不会直接数据应用到自己的系统，而是先向所有的Follower发送请求，让他们先处理这个请求
当超过半数的Follower成功处理了这个写请求之后，Leader才会写数据，并返回给客户端请求处理成功
如果超过一定时间未收到超过半数处理成功Follower的信号，此时Leader认为这次写数据是失败的，就不会处理写请求，直接返回给客户端请求失败。



我们日常使用中可以将部署在相同区域的服务划分为同一个集群，比如杭州属于一个集群，上海属于一个集群

这样服务调用的时候，就可以优先使用同一个地区的服务了，比跨区域调用速度更快。












